{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Feb 25 2019, Will Holmgren\n",
    "https://stackoverflow.com/questions/54839422/how-can-pvlib-python-retreive-a-year-long-archived-weather-forecasts-from-the-gl\n",
    "\n",
    "However, I wrote a python script to download some archived point forecast data from the NOAA NOMADS server:\n",
    "https://github.com/wholmgren/get_nomads/ It's efficient in that in only downloads the data that you need, but it's still fairly\n",
    "slow and error prone.\n",
    "\n",
    "https://github.com/wholmgren/get_nomads/blob/master/get_nomads.py\n",
    "\n",
    "# Get NOMAD from NOAA\n",
    "A script to download weather forecast point data that is relevant to\n",
    "solar power. Data is from the GFS model data hosted on the NOAA NOMADS\n",
    "server. The script saves the data in a csv file.\n",
    "The script supports simultaneous queries of different initialization times.\n",
    "Run ``python get_nomads.py -h`` to see usage options.\n",
    "Written by Will Holmgren, January 2017.\n",
    "Copyright University of Arizona Board of Regents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool, TimeoutError\n",
    "\n",
    "from pydap.client import open_url\n",
    "from webob.exc import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other variables of interest are commented out for efficiency\n",
    "\n",
    "MODEL_DEFAULTS = {\n",
    "    'gfs4': {\n",
    "        'variables': (\n",
    "            'Temperature_surface',\n",
    "            # 'Wind_speed_gust',\n",
    "            'U-component_of_wind',\n",
    "            'V-component_of_wind',\n",
    "            'Total_cloud_cover_entire_atmosphere',\n",
    "            # 'Total_cloud_cover_high_cloud',\n",
    "            # 'Total_cloud_cover_low_cloud',\n",
    "            # 'Total_cloud_cover_middle_cloud',\n",
    "            # 'Downward_Short-Wave_Rad_Flux'\n",
    "        ),\n",
    "        'model_route': 'gfs-004',\n",
    "        'file_prefix': 'gfs_4',\n",
    "        'time_resolution': 3,\n",
    "        'grib_format': 'grb2',\n",
    "        'max_hours': 384\n",
    "    },\n",
    "    'nam218': {\n",
    "        'variables': (\n",
    "            'Temperature_surface',\n",
    "            'u_wind_height_above_ground',\n",
    "            'v_wind_height_above_ground',\n",
    "            'Total_cloud_cover',\n",
    "            'Downward_short_wave_flux'\n",
    "        ),\n",
    "        'model_route': 'nam218',\n",
    "        'file_prefix': 'nam_218',\n",
    "        'time_resolution': {1: (1, 36), 3: (39, 84)},\n",
    "        'grib_format': 'grb',\n",
    "        'max_hours': 84,\n",
    "    },\n",
    "    'rap130': {\n",
    "        'variables': (\n",
    "            'Temperature_surface',\n",
    "            'U-component_of_wind_height_above_ground',\n",
    "            'V-component_of_wind_height_above_ground',\n",
    "            'Total_cloud_cover',\n",
    "            # 'Downward_short_wave_flux'\n",
    "        ),\n",
    "        'model_route': 'rap130',\n",
    "        'file_prefix': 'rap_130',\n",
    "        'time_resolution': 1,\n",
    "        'grib_format': 'grb2',\n",
    "        'max_hours': 18\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_times(init_timestamp, hours, lat_idx, lon_idx, variables,\n",
    "                   model_route, file_prefix, time_resolution, grib_format):\n",
    "    route = f'https://nomads.ncdc.noaa.gov/thredds/dodsC/{model_route}/'\n",
    "    init_timestr = init_timestamp.strftime(\n",
    "        f'%Y%m/%Y%m%d/{file_prefix}_%Y%m%d_%H%M')\n",
    "\n",
    "    multiple_time_data = {}\n",
    "\n",
    "    if isinstance(time_resolution, dict):\n",
    "        pass\n",
    "    else:\n",
    "        time_resolution = {time_resolution: (time_resolution, hours)}\n",
    "\n",
    "    for res, (start, end) in time_resolution.items():\n",
    "        end = end + 1\n",
    "        for fx_hour in range(start, end, res):\n",
    "            full_uri = (\n",
    "                '{route}{init_timestr}_{fx_hour:0>3}.{grib_format}'.format(\n",
    "                route=route, init_timestr=init_timestr, fx_hour=fx_hour,\n",
    "                grib_format=grib_format))\n",
    "            logging.info('getting data from %s', full_uri)\n",
    "            dataset = open_url(full_uri)\n",
    "            fx_timestamp = init_timestamp + pd.Timedelta(fx_hour, unit='h')\n",
    "            try:\n",
    "                single_time_data = single_time(dataset, lat_idx, lon_idx,\n",
    "                                               variables)\n",
    "            except HTTPError as e:\n",
    "                logging.warning('error getting %s retrying in 30s.', full_uri)\n",
    "                time.sleep(30)\n",
    "                try:\n",
    "                    single_time_data = single_time(dataset, lat_idx, lon_idx,\n",
    "                                                   variables)\n",
    "                except HTTPError as e:\n",
    "                    logging.warning(\n",
    "                        '2nd error getting %s retrying in 30s.', full_uri)\n",
    "                    time.sleep(30)\n",
    "                    single_time_data = single_time(dataset, lat_idx, lon_idx,\n",
    "                                                   variables)\n",
    "            except KeyError as e:\n",
    "                logging.error('KeyError in %s', full_uri)\n",
    "\n",
    "            try:\n",
    "                multiple_time_data[fx_timestamp] = single_time_data\n",
    "            except UnboundLocalError:\n",
    "                logging.error('no data for %s', full_uri)\n",
    "\n",
    "    return multiple_time_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_time(dataset, lat_idx, lon_idx, variables):\n",
    "    datad = {}\n",
    "    for var in variables:\n",
    "        datavar = dataset[var]\n",
    "        data = get_datavar(datavar.array, var, lat_idx, lon_idx)\n",
    "        datad[var] = np.asscalar(data)\n",
    "    return datad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datavar(datavar, var, lat_idx, lon_idx, is_retry=0):\n",
    "    \"\"\"Makes a http request for data and returns it.\n",
    "    Calls itself up to 10 times if there's a network failure.\n",
    "    \"\"\"\n",
    "    max_retry = 10\n",
    "    sleep_time = 30\n",
    "\n",
    "    if is_retry > max_retry:\n",
    "        raise HTTPError('exceeded maximum retry attempts for %s', datavar)\n",
    "\n",
    "    try:\n",
    "        if 'wind' in var:\n",
    "            data = datavar[0, 0, lat_idx, lon_idx]\n",
    "        else:\n",
    "            data = datavar[0, lat_idx, lon_idx]\n",
    "    except (HTTPError, OSError) as e:\n",
    "        logging.warning('error %s getting %s, retrying in %s s',\n",
    "                        is_retry, datavar, sleep_time)\n",
    "        time.sleep(sleep_time)\n",
    "        data = get_datavar(datavar, var, lat_idx, lon_idx, is_retry=is_retry+1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataframe(multiple_time_data):\n",
    "    index = pd.DatetimeIndex(sorted(multiple_time_data), tz='UTC')\n",
    "\n",
    "    df = defaultdict(list)\n",
    "    for k, v in sorted(multiple_time_data.items()):\n",
    "        for var, data in v.items():\n",
    "            df[var].append(data)\n",
    "    df = pd.DataFrame(df, index=index)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_forecast(init_time, args):\n",
    "    init_timestamp = pd.Timestamp(init_time)\n",
    "\n",
    "    model_defaults = MODEL_DEFAULTS[args.model]\n",
    "\n",
    "    multiple_time_data = multiple_times(init_timestamp, args.hours,\n",
    "                                        args.lat_idx, args.lon_idx,\n",
    "                                        model_defaults['variables'],\n",
    "                                        model_defaults['model_route'],\n",
    "                                        model_defaults['file_prefix'],\n",
    "                                        model_defaults['time_resolution'],\n",
    "                                        model_defaults['grib_format'])\n",
    "\n",
    "    df = construct_dataframe(multiple_time_data)\n",
    "\n",
    "    output_file = init_timestamp.strftime('%Y%m%dT%H%M') + '.out' + '.csv'\n",
    "    output_abspath = os.path.join(args.output_dir, output_file)\n",
    "    df.to_csv(output_abspath)\n",
    "    return output_abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    argparser = argparse.ArgumentParser(\n",
    "        description='Download forecast data from NOMADS and export as csv')\n",
    "    argparser.add_argument('-i', '--init-time',\n",
    "                           help='initialization timestamp', action='append')\n",
    "    argparser.add_argument('--hours', help='number of forecast hours',\n",
    "                           default=24, type=int)\n",
    "    argparser.add_argument('--init-time-start', help='first init-time')\n",
    "    argparser.add_argument('--init-time-periods', help='number of init-times',\n",
    "                           type=int)\n",
    "    argparser.add_argument('--init-time-freq', help='frequency of init-times')\n",
    "    argparser.add_argument('--lat-idx', help='latitude index', type=int)\n",
    "    argparser.add_argument('--lon-idx', help='longitude index', type=int)\n",
    "    argparser.add_argument('--output-dir', help='output file',\n",
    "                           default=None)\n",
    "    argparser.add_argument('-v', '--verbose',\n",
    "                           help='Increase logging verbosity',\n",
    "                           action='count')\n",
    "#     argparser.add_argument('--variables',\n",
    "#                            help='forecast variables (comma separated)',\n",
    "#                            default=DEFAULT_VARIABLES)\n",
    "    argparser.add_argument('--timeout', help='request timeout', type=int,\n",
    "                           default=None)\n",
    "    argparser.add_argument('--processes', help='number of processes', type=int,\n",
    "                           default=8)\n",
    "    argparser.add_argument('--model', help='name of model',\n",
    "                           default='gfs4',\n",
    "                           choices=['gfs4', 'nam218', 'rap130'])\n",
    "    # pydap cache not working https://github.com/pydap/pydap/pull/37\n",
    "    # argparser.add_argument('-c', '--cache', help='pydap cache', default=None)\n",
    "\n",
    "    args = argparser.parse_args()\n",
    "\n",
    "    if args.init_time_start is not None:\n",
    "        args.init_time = pd.DatetimeIndex(start=args.init_time_start,\n",
    "                                          freq=args.init_time_freq,\n",
    "                                          periods=args.init_time_periods)\n",
    "\n",
    "    args.output_dir = args.output_dir or os.getcwd()\n",
    "\n",
    "    process_sets = np.ceil(len(args.init_time) / args.processes)\n",
    "    args.timeout = args.timeout or int(args.hours * 60 / 3 * process_sets)\n",
    "\n",
    "    # pydap.lib.CACHE = args.cache\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(init_times, args, p):\n",
    "    multiple_results = {\n",
    "        init_time: p.apply_async(single_forecast, args=(init_time, args))\n",
    "        for init_time in init_times}\n",
    "\n",
    "    successes = []\n",
    "    failures = []\n",
    "    for init_time, res in multiple_results.items():\n",
    "        try:\n",
    "            res.get(timeout=args.timeout)\n",
    "        except (HTTPError, TimeoutError, OSError, IndexError, AttributeError):\n",
    "            logging.exception('failed to get forecast for %s', init_time)\n",
    "            failures.append(init_time)\n",
    "        else:\n",
    "            logging.info('succeeded in getting forecast for %s', init_time)\n",
    "            successes.append(init_time)\n",
    "\n",
    "    logging.info('successes:\\n%s', successes)\n",
    "    logging.critical('failures:\\n%s', failures)\n",
    "\n",
    "    return failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-i INIT_TIME] [--hours HOURS]\n",
      "                             [--init-time-start INIT_TIME_START]\n",
      "                             [--init-time-periods INIT_TIME_PERIODS]\n",
      "                             [--init-time-freq INIT_TIME_FREQ]\n",
      "                             [--lat-idx LAT_IDX] [--lon-idx LON_IDX]\n",
      "                             [--output-dir OUTPUT_DIR] [-v]\n",
      "                             [--timeout TIMEOUT] [--processes PROCESSES]\n",
      "                             [--model {gfs4,nam218,rap130}]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Mhdella\\AppData\\Roaming\\jupyter\\runtime\\kernel-f24cea68-c4b6-4f79-9bf2-354b8daa3cdf.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mhdella\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    logging.basicConfig(level=logging.WARNING,\n",
    "                        format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "    args = parse_args()\n",
    "\n",
    "    if args.verbose == 1:\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "    elif args.verbose and args.verbose > 1:\n",
    "        logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    with Pool(processes=args.processes) as p:\n",
    "        failures = execute(args.init_time, args, p)\n",
    "        if len(failures):\n",
    "            logging.warning('retrying failed init times')\n",
    "            failures = execute(failures, args, p)\n",
    "            logging.critical('repeated failures:\\n%s', failures)\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
